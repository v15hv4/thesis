\section{Problem Definition} 
Our study aims to computationally design novel, stable peptide binders that form high-affinity complexes with specific receptor protein binding pockets.
We represent the binding pocket as a set of atoms, $P = \{x_P^i, v_P^i\}$, where $x_P^i$ denotes the three-dimensional Cartesian coordinates of each atom in the protein, and $v_P^i$ signifies its corresponding feature vector. The chosen feature vector, $v_P^i$, specifically encodes the atom type and its associated amino acid residue. Following this, we aim to generate peptides represented as $M = \{x_M^i, v_M^i\}$. Here, $x_M^i$ corresponds to the 3D Cartesian coordinates of each atom within the peptide, and $v_M^i$ signifies its feature vector, similarly encoding atom type and the corresponding amino acid residue it belongs to.

\section{HYDRA}
To promote the generation of chemically stable peptides for the target receptor, HYDRA employs a two-stage process: (1) amino acid residue generation using a diffusion model and (2) peptide reconstruction with binding affinity optimization, as illustrated in Figure TODO. This necessitates an intermediate representation for the generated residues following the first stage. We represent this intermediate state as $A = {x_A^i, v_A^i}$, where $x_A^i$ denotes the center-of-mass for each amino acid in the putative peptide and $v_A^i$ encodes the corresponding amino acid type. Subsequently, the second stage utilizes this intermediate representation as input to reconstruct the final peptide, aiming to maximize its predicted binding affinity towards the target receptor.

\subsection{Prior-Based Residue Count Estimation}
Since the generative diffusion process is non-autoregressive, unlike sequential generation models, the total number of residues within the protein pocket cannot be determined incrementally during the generation phase. To address this, we precompute a prior distribution for the number of residues based on the training data. \\

The prior distribution leverages the concept of pocket size. First, we calculate the top 10 furthest pairwise distances between protein atoms within each pocket in the training set. This step captures the range of pocket sizes encountered in the training data. To mitigate the influence of potential outliers, we select the median value from these top 10 distances as a robust estimate of the pocket size for each training pocket. Next, we subdivide the range of observed pocket sizes into 10 quantiles. This discretization step creates 10 bins, each representing a specific pocket size range. For each bin, we leverage the histogram of the number of amino acids within training pockets falling within that specific size range. This histogram serves as the prior distribution for the number of residues to be generated within pockets of similar size during the diffusion process. During generation, the non-autoregressive diffusion model requires the number of residues to be determined upfront.  We achieve this by randomly sampling from the precomputed prior distributions associated with the estimated pocket size for the protein being generated. This approach ensures that the generated protein sequences have a realistic number of residues based on the pocket size to which it is expected to bind.

\subsection{Residue Generation}
Deep generative modeling has recently surged in popularity due to its ability to generate novel, high-fidelity data across various domains, from drug discovery to artistic creation. Among deep generative models, diffusion models are gaining prominence due to their ability to effectively generate realistic data through a denoising process. Diffusion models are inspired by non-equilibrium thermodynamics \cite{sohl2015deep, ho2020denoising} and employ a sequential process of noise injection and denoising to learn the underlying distribution of data. During training, the model progressively adds Gaussian noise to real data points, gradually transforming them into isotropic Gaussian noise. This process is modeled as a Markov chain with T discrete steps. Leveraging the Markovian property, the model can efficiently compute the probability density at any given step $t$ solely based on the probability density at the preceding step $t-1$. \\

Diffusion models have emerged as a promising approach in drug design due to their ability to generate diverse and high-quality 3D molecular structures in a non-autoregressive fashion \cite{du2022molgensurvey} as an improvement over sequence-based molecule generation models that make use of Simplified Molecular-Input Line-Entry System (SMILES) \cite{weininger1988smiles} representations that lack detailed spatial information. Inspired by the success of diffusion models in creating 3D molecular structures, we explored their potential in generating peptide shapes specifically designed to fit into target binding pockets. For conciseness, we represent a peptide as a set of amino acid residues $A = [x, v]$, where $[\cdot, \cdot]$ is the concatenation operator, $x \in \mathbb{R}^{R \times 3}$ denotes the 3D Cartesian coordinates of the center-of-mass of each amino acid residue, and $v \in \mathbb{R}^{R \times K}$ denotes the one-hot encoded amino acid residue type. \\

We use a Gaussian distribution ($\mathcal{N}$) for the continuous coordinates and a categorical distribution ($\mathcal{C}$) for the discrete residue types represented as one-hot vectors. The residue distribution is modeled as a product of these individual distributions. A small Gaussian noise and a uniform noise across all categories are added to the coordinates and types, respectively, at each time step $t$:
$$q(A_t|A_{t-1}|P)=\mathcal{N}(x_t;\sqrt{1-\beta_t};x_{t-1},\beta_t I) \cdot \mathcal{C}(v_t|(1-\beta_t)v_{t-1}+\beta_t/K)$$
Here, $\beta_i$ denotes fixed variance schedules, which may differ in practice but are denoted with the same symbol for maintaining conciseness. By employing the reparameterization trick and taking $\alpha_t = 1 - \beta_t$ and $\bar{\alpha_t} = \Pi_{s=1}^t \alpha_s$, the iterative noise injection process can be significantly accelerated. $A_t$ can now be represented as:
$$A_t =\sqrt{\alpha_t}A_{t-1} + \sqrt{1-\alpha_t}\epsilon_{t-1}
= \sqrt{{\alpha_t}\alpha_{t-1}}A_{t-2} + \sqrt{1-\alpha_t\alpha_{t-1}}\bar{\epsilon}_{t-2} = \cdots = \sqrt{\bar{\alpha}_t}A_0 + \sqrt{1-\bar{\alpha}_t}\epsilon$$
Here, $\epsilon_{t-1}, \epsilon_{t-2}, \ldots$ are noise from $\mathcal{N}(0, I)$ and $\epsilon$ combines the noise terms. Consequently
$$q(x_t|x_0)=\mathcal{N}(x_t;\sqrt{\bar{\alpha_t}}x_0, (1-\bar{\alpha_t})I)$$
$$q(v_t|v_0)=\mathcal{C}(v_t|\bar{\alpha_t}v_0 + (1-\bar{\alpha_t})/K)$$

In the denoising process, we aim to recover the initial peptide, $A_0$, from the final noisy state, $A_T$. However, directly calculating the exact reverse distribution added with the noise is intractable. To address this, we employ a neural network parameterized by $\theta$ to approximate this reverse distribution. \\
$$P_{\theta}(A_{t-1}|A_t, P)=\mathcal{N}(x_{t-1};\mu_{\theta}([x_t, v_t], t, P), \sigma_t^2I) \cdot \mathcal{C}(v_{t-1}|c_\theta([x_t, v_t], t, P)$$

Crucially, this generative process must be invariant to rotations and translations of the protein-peptide complex. This inductive bias ensures consistent likelihood predictions $P_{\theta}(A_0|P)$, essential for accurate 3D peptide structure generation. As informed by existing literature \cite{kohler2020equivariant, xu2022geodiff}, the Markov transition $P_\theta(A_{t-1} |A_t, P_b)$ must be SE(3)-equivariant and the initial density of our generative process, $P(A_T|P_b)$, is SE(3)-invariant. We need to take into account the amino acid residue coordinates because, during the generative process, atom types are always invariant to SE(3)-transformation. Here, we model $[x_0, v_0]$ to get $\mu_{\theta}([x_t, v_t], t, P)$ and $c_\theta([x_t, v_t], t, P)$.  \\

At the $l$-th layer, the hidden embedding \textbf{h} and coordinates \textbf{x} of the amino acid residues are updated alternately as follows:
$$h_i^{l+1} = h_i^l + \Sigma_{j \in V, i\neq j}  f_h(d_{ij}^i, h_i^l, h_j^l, e_{ij}; \theta_h)$$
$$x_i^{l+1} = x_i^l + \Sigma_{j \in V, i\neq j} (x_i^l - x_j^l)  f_x(d_{ij}^i, h_i^{l+1}, h_j^{l+1}, e_{ij}; \theta_x).\mathbbm{1}_{pep}$$

Here, $d_{ij}$ is the Euclidean distance between residues $i$ and $j$, and $e_{ij}$ denotes a connection between these residues. We use a mask $\mathbbm{1}_{pep}$ in order to refrain from updating protein atom coordinates. The initial residue embedding \textbf{h$^0$} is obtained from an embedding layer that encodes the amino acid information, and the final residue embedding \textbf{h$^L$} is used to obtain the final peptide features through a Multi-Layer Perceptron and a Softmax function. \\

We train the model by minimizing the variational bound on the negative log-likelihood. Due to the Gaussian nature of $q(x_{t-1}|x_t, x_0)$ and $P_{\theta}(x_{t-1}|x_t)$, the KL-divergence for the coordinate loss admits the closed-form expression:
$$L_{t-1}^x = \frac{1}{2\sigma_t^2} \Vert{\tilde{\mu_t(x_t, x_0)} - \mu_{\theta}([x_t, v_t], t, P)}\Vert^2 + C = \gamma_t\Vert{x_0 - \hat{x_0}}\Vert^2 + C$$
Here, $\gamma_t = \bar{\alpha_{t-1}}\beta_t^2/2\sigma_t^2(1-\bar{\alpha_t)}^2$ and C is a constant. In practice, training the model with $\gamma_t = 1$ could achieve better performance \cite{ho2020denoising}. We compute the residue type loss directly using the KL-divergence for categorical distributions, given by:
$$L_{t-1}^v = \Sigma_{k} c(v_t, v_0)_{k} \log c(v_t, v_0)_{k}/c(v_t, \hat{v_0})_{k}$$

The overall loss function is formulated as a weighted combination of the residue coordinate loss and the residue type loss:
$$L = L_{t-1}^x + \lambda L_{t-1}^v$$

\subsection{Peptide Reconstruction}

Following the generation of individual amino acid residues, the next step involves assembling them in the correct sequential order to form complete peptides. This reconstruction process effectively translates the intermediate state $A$ into the final peptide sequences represented by $M$. To achieve chemically stable protein-peptide complexes, we prioritize the identification of optimal residue connectivity patterns within the generated peptides. This optimization process maximizes the binding affinity of the connected peptide with the target receptor, thereby promoting complex stability. To achieve this, we first compute the distance matrix $\mathbf{D}_{n \times n}$ such that
$$d_{ij} = \sqrt{(x_i - x_j)^2 + (y_i - y_j)^2 + (z_i - z_j)^2}$$

Here, $n$ denotes the number of amino acid residues generated that form the peptide, and $d_{ij}$ denotes each element of the distance matrix that represents Euclidean distance between the centers of mass of residue $i$ and residue $j$ in 3D space. Due to the symmetry of the distance matrix, the lower triangle can be ignored, leaving $\frac{n \times (n-1)}{2}$ possible edges in the solution space. Following the initial edge identification, a filtering step is applied to eliminate connections exceeding a biologically relevant distance threshold. This step prioritizes the generation of peptides with realistic conformations, as the chemical nature of peptide bonds restricts the maximum distance attainable between adjacent amino acids. \\
The reconstruction process generates a distance matrix encompassing all potential inter-residue edges. However, due to the inherent limitations of peptide bond lengths, connections between residues positioned far apart in 3D space are physically implausible. To address this, we employ a distance threshold to eliminate unrealistic edges. \\

The threshold value is meticulously chosen based on the training data. We calculated the distances between the center of mass for each residue pair within the training complexes. Figure TODO illustrates the distribution of inter-residue distances of peptides in the training data. This analysis revealed that over 99\% of inter-residue distances fell below 8Å. Consequently, a threshold of 8Å was established to effectively filter out improbable connections during reconstruction. \\
The solution space is reduced to M possible edges following the distance-based thresholding. However, selecting $(n-1)$ edges from this set to define the final peptide structure remains challenging. Each edge specifies a connection between residues $i$ and $j$, but its directionality determines which residue harbors the C-terminus and, consequently, which residue holds the N-terminus upon bonding.  \\

Construction of a candidate peptide from a chosen set of edges and their directionalities involves a two-stage process. First, the amino acid residues are virtually placed at their predicted center-of-mass positions, and peptide bonds are formed between residues based on the chosen edges, establishing the initial peptide structure. This initial structure then undergoes energy minimization using a Merck Molecular Force Field (MMFF) \cite{halgren1996merck} to optimize its geometry and achieve a more relaxed, lower-energy conformation. The resulting structure represents the fully reconstructed candidate peptide. Subsequently, the binding affinity between this peptide and the target receptor is assessed using AutoDock Vina \cite{trott2010autodock}. This software performs a local structure optimization of the peptide within the target binding pocket. The optimization employs the Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm \cite{head1985broyden}, followed by the calculation of binding affinity using the Vina Scoring Function \cite{trott2010autodock}:
$$\Delta G = w_{vina}(E_{vd}+ E_{elec} + E_{hbond}) + w_gE_g + w_hE_h$$

The Vina Scoring Function incorporates the following terms: $E_{vd}$, representing the van der Waals interaction energy; $E_{elec}$, denoting the electrostatic interaction energy; $E_{hbond}$, accounting for the hydrogen bonding interaction energy; $E_g$, the torsional free energy; and $E_h$, a reference state correction term. These terms are weighted by coefficients $w_{vina}$, $w_g$, and $w_h$, respectively, which were optimized and assigned during the training of the scoring function \cite{trott2010autodock}. \\

To identify the peptide with the best binding affinity, an exhaustive evaluation of $2 \cdot {s \choose n-1}$ possible amino acid configurations would be required. This becomes computationally intractable as the peptide length ($n$) and, consequently, the solution space size ($s \geq (n-1)$) increases due to the high cost associated with construction, local structure optimization, and binding affinity calculations. This extensive search space necessitates a heuristic-based approach to guide the search towards promising regions. The peptide reconstruction process inherently lacks a differentiable objective function due to discrete steps in establishing the initial peptide structure, energy minimization using a force field, and local structure optimization through MMFF. Consequently, gradient-based optimization methods become inapplicable. We opted for a heuristic optimization approach, which treats the objective function as a "black box" and iteratively refines candidate solutions based on their performance within this function. Several no-gradient stochastic optimization algorithms were evaluated, including Genetic Algorithms \cite{holland1992adaptation}, Simulated Annealing \cite{kirkpatrick1983optimization}, and Particle Swarm Optimization (PSO) \cite{eberhart1995new, kennedy1995particle}. Binary Particle Swarm Optimization (BPSO) emerged as our preferred choice as we observed faster convergence while achieving comparable results to other methods. \\

PSO utilizes a population of candidate solutions (particles) representing potential peptide bonds. Each particle has a position in the search space and a velocity guiding its movement. The objective function, which consists of constructing the peptide from the candidate bonds and computing its binding affinity, acts as a fitness function, evaluating each particle's suitability. Particles track their personal best ($p_{best}$) position, and the swarm maintains a global best ($g_{best}$) position found by any particle. Particle velocities are updated iteratively based on their current state, attraction to their $p_{best}$, and attraction to the $g_{best}$. This guides them toward promising areas of the search space. Positions are updated based on the new velocity, followed by fitness evaluation. If a particle finds a better position than its $p_{best}$, it updates its $p_{best}$. The $g_{best}$ is updated if a particle discovers a superior position. This cycle repeats for several iterations, allowing the swarm to converge towards optimal solutions iteratively. Binary Particle Swarm Optimization (BPSO) is an implementation of the PSO algorithm where the particles are restricted to the binary domain. A detailed example of the reconstruction workflow for a peptide consisting of 5 amino acid residues is illustrated in Figure TODO.

\section{\textit{In Silico} Assessment Criteria for Designed Peptides}
Upon generation, we conducted a comprehensive computational evaluation of the generated peptides. This evaluation aimed to assess their potential as functional drug molecules in various applications. We employed various computational tools to analyze crucial physicochemical properties and binding affinities relevant to their potential therapeutic efficacy.

\subsection{Physicochemical Properties}
Physicochemical properties are critical determinants of a peptide's suitability as a therapeutic agent. For example, an important factor that determines their effectiveness as drugs is their half-life \cite{nugrahadi2023designing}, which refers to the time it takes for half of the peptide to be broken down or eliminated from the body. Peptides with longer half-lives can exhibit their therapeutic effects over a longer time, which can be especially important for medications that require prolonged activity to be effective. Peptides often contain a mix of hydrophilic and hydrophobic amino acids, which can affect their solubility and interaction with cell membranes \cite{madani2011mechanisms}. This can impact their ability to pass through cell membranes and work effectively inside cells. Peptides with a slightly higher percentage of hydrophobic residues may have increased cell permeability \cite{madani2011mechanisms} and be more effective at interacting with cell membranes, as hydrophobic residues can interact very well with the hydrophobic regions of lipid bi-layers, enhancing the transit of the peptide across cell membranes \cite{madani2011mechanisms}. Given the importance of physicochemical properties for therapeutic applications, we evaluated those of the generated peptides. The following properties were assessed:

\subsubsection*{I. Molecular Weight (MW)}
The molecular weight of each peptide was calculated and compared to the established range (500-5000 Da) characteristic of drug-like peptides \cite{erckes2022story}. This parameter significantly influences a peptide's solubility, membrane permeability, and potential for toxicity. Peptides falling outside this range might exhibit undesirable pharmacological properties, hindering their potential as viable drug candidates.

\subsubsection*{II. Isoelectric Point (pI)}
The pI of each peptide was determined, reflecting the specific pH at which the molecule possesses a net neutral charge. This property is crucial in determining a peptide's solubility, stability, and interactions with biological targets. Peptides with pI values outside the physiological pH range (7.4) might exhibit reduced solubility and stability in biological environments, compromising their therapeutic efficacy \cite{frolov2022pichemist}.

\subsubsection*{III. Half-life ($t_{1/2}$)}
The half-life of a drug is the duration required for a drug's concentration in the bloodstream (or any other pertinent compartment) to drop by half. The half-life of each peptide was calculated with respect to in-vitro conditions in mammalian reticulocytes. This parameter is critical for determining the efficacy and duration of action of a potential drug. Peptides with shorter half-lives might require more frequent administration to maintain their therapeutic effect, whereas those with longer half-lives could potentially offer sustained drug action, reducing dosing frequency and improving patient compliance. Most peptides have \textit{in vivo} half-lives of 2–30 minutes due to protease enzymatic breakdown and quick renal clearance (molecules smaller than 30 kDa are quickly eliminated by glomerular filtration) \cite{penchala2015biomimetic}. Consequently, increasing the \textit{in vivo} half-life of peptides to fulfill their therapeutic potential without requiring high dosages or frequent administration is desirable \cite{penchala2015biomimetic}. 

\subsubsection*{IV. Instability Index (II)}
The instability index, based solely on the amino acid sequence of each peptide, was calculated using the formula $\frac{10}{L}\sum_{i=1}^{L} \left[\frac{1}{log(f_i)}\right] $, where L is the length of the protein sequence and $f_i$ is the dipeptide frequency of occurrence for each dipeptide in the protein sequence. A peptide's instability index is a numerical value that indicates how stable a protein or peptide will be \cite{Guruprasad1990}. Proteins or peptides are generally classified as stable if their instability index is lower than 40 and unstable if it is 40 or above \cite{Guruprasad1990}. Stable peptides are generally preferred for drug development due to their longer shelf life and potential for sustained activity \textit{in vivo}. Peptides with high instability indices might undergo rapid degradation, limiting their therapeutic potential.

\subsubsection*{V. Aliphatic Index (AI)}
The aliphatic index, reflecting a peptide's overall hydrophobicity, is determined by calculating the proportionate volume that aliphatic side chains (Leucine, Isoleucine, Valine, and Alanine) occupy in a protein or peptide \cite{panda2012physicochemical}. Due to the presence of hydrophobic interactions, peptides with higher AI may display improved structural stability, contributing to their overall stability, which is crucial for a therapeutic peptide to remain active. Peptides with higher AI values might also have higher membrane permeability, enabling them to reach intracellular targets effectively \cite{panda2012physicochemical}.

\subsubsection*{VI. Grand Average of Hydropathy (GRAVY)}
GRAVY is a numeric representation of a protein or peptide sequence's total hydrophobicity or hydrophilicity. This value is determined by the sum of the hydropathy of all amino acids divided by the total number of amino acids \cite{kyte1982simple}. This value can be positive, negative, or zero. Positive GRAVY values indicate a hydrophobic sequence, whereas negative values show a hydrophilic sequence. A GRAVY near zero indicates a sequence with a balance of hydrophobic and hydrophilic residues. Positive GRAVY values indicate the sequence is dominated by hydrophobic residues, which may reduce the peptide's solubility in aqueous solutions. Particularly at high concentrations, hydrophobic residues tend to group to minimize interaction with water molecules, which can cause protein aggregation. Hydrophobic residues can interact very well with the hydrophobic part of lipid bilayers, enhancing the transit of the peptides across cell membranes, which may have increased cell permeability. Extremely high hydrophobicity, however, may result in non-specific interactions with cell membranes that compromise the integrity of the membrane and impair cellular processes \cite{kyte1982simple}. Negative GRAVY values indicate higher solubility in aqueous solutions because of the greater interactions with water molecules.

\subsection{Binding Affinity}
Peptides exhibiting high binding affinity towards their target are more likely to disrupt crucial disease-associated processes and achieve therapeutic outcomes successfully. We assessed the binding affinity of each peptide towards its intended target using AutoDock Vina \cite{trott2010autodock} and FRODOCK \cite{Aportela2016}.

\subsubsection*{I. AutoDock Vina}
AutoDock Vina is a widely used program for molecular docking \cite{trott2010autodock}. It employs an empirical scoring function to estimate binding affinity, considering factors like hydrophobic interactions, hydrogen bonding, and electrostatics. Lower scores (in kcal/mol) indicate stronger predicted binding. Vina then performs local structure optimization using the Steepest Descent algorithm to refine the ligand's pose within the binding pocket, seeking the pose with the lowest binding energy. While these scores are estimates, Vina provides a valuable tool for exploring potential ligand-receptor interactions \cite{trott2010autodock}. While AutoDock Vina excels at docking small molecules, its exhaustive search for optimal conformations becomes computationally inefficient for longer peptides due to their increased conformational space \cite{rentzsch2015docking}. However, in this work, we circumvent this limitation by leveraging Vina's efficient scoring function for local optimization. We bypass the initial docking step, assuming pre-defined peptide poses within the protein-peptide complex. This allows us to exploit Vina's established capabilities for protein-peptide interaction energy calculations without incurring the full computational cost associated with peptide conformational sampling.

\subsubsection*{II. FRODOCK}
FRODOCK, or Fast Rotational DOCKing, is an approach for protein-protein docking simulations \cite{Aportela2016}. Unlike AutoDock Vina, which uses an empirical scoring function, FRODOCK employs a correlation function for protein-protein docking. This function assesses the overlap of interaction patterns (e.g., hydrophobicity, electrostatics) between protein surfaces, with higher scores indicating greater potential for favorable interactions but not directly reflecting binding affinity. This distinction highlights the importance of selecting the appropriate docking tool based on the specific type of molecular interaction under investigation \cite{Aportela2016}.  \\

Utilizing two distinct scoring functions helps mitigate potential biases inherent to any single method and provides a more robust evaluation of predicted binding affinity. 
A comparison between different aggregations of these metrics computed for relevant datasets can be found below. (TODO: attach figures from supplementary)

\subsection{Diversity}
We quantify the diversity of the generated peptide sets using the average pairwise Tanimoto distance \cite{bajusz2015sim, tanimoto1958elementary}. This metric assesses the similarity between peptide pairs by considering the presence or absence of specific amino acids at each sequence position. Higher average Tanimoto distances indicate a more diverse peptide set capable of exploring a wider range of potential binding interactions.
